{"cells":[{"cell_type":"markdown","metadata":{"id":"HPUlClX7zcGv"},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1644650697956,"user":{"displayName":"Nisarg Khacharia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhU9oWwobGpgFORhEv1KqSZ0ib2zhbu4wHOtw6uhA=s64","userId":"12217861741112456528"},"user_tz":-330},"id":"zdGWPGpQzcG1"},"outputs":[],"source":["import cv2\n","import numpy as np \n","import os\n","import matplotlib.pyplot as plt\n","import time \n","import mediapipe as mp "]},{"cell_type":"markdown","metadata":{"id":"gmeXPudGzcG2"},"source":["# Keypoints using MP Holistic"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1644650701149,"user":{"displayName":"Nisarg Khacharia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhU9oWwobGpgFORhEv1KqSZ0ib2zhbu4wHOtw6uhA=s64","userId":"12217861741112456528"},"user_tz":-330},"id":"vAEfAEPJzcG3"},"outputs":[],"source":["mp_holistic = mp.solutions.holistic  # holistic model\n","mp_drawing = mp.solutions.drawing_utils #drawing utilities"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":369,"status":"ok","timestamp":1644650704125,"user":{"displayName":"Nisarg Khacharia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhU9oWwobGpgFORhEv1KqSZ0ib2zhbu4wHOtw6uhA=s64","userId":"12217861741112456528"},"user_tz":-330},"id":"HD860ghmzcG3"},"outputs":[],"source":["def mediapipe_detection(image, model):\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image.flags.writeable = False         # image not writeable\n","    results = model.process(image)\n","    image.flags.writeable = True          # image writeable\n","    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","    return image, results"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":360,"status":"ok","timestamp":1644650706785,"user":{"displayName":"Nisarg Khacharia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhU9oWwobGpgFORhEv1KqSZ0ib2zhbu4wHOtw6uhA=s64","userId":"12217861741112456528"},"user_tz":-330},"id":"DYergDUwzcG4"},"outputs":[],"source":["def draw_landmarks(image, results, face=False):\n","    if face == True:\n","        # Draw face connections\n","        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n","                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n","                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n","                                 ) \n","        # Draw pose connections\n","        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n","                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n","                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n","                                 ) \n","    # Draw left hand connections\n","    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n","                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n","                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n","                             ) \n","    # Draw right hand connections  \n","    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n","                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n","                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n","                             ) "]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cln5L5WKzcG5"},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","# Set mediapipe model \n","with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n","    while cap.isOpened():\n","    \n","        # Read feed\n","        ret, frame = cap.read()\n","\n","        # Make detections\n","        image, results = mediapipe_detection(frame, holistic)\n","        \n","        # Draw landmarks\n","        draw_landmarks(image, results, face=True)\n","\n","        # Show to screen\n","        cv2.imshow('OpenCV Feed', image)\n","\n","        # Break gracefully\n","        if cv2.waitKey(10) & 0xFF == 27:\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["cv2.destroyAllWindows()\n","cap.release()"]},{"cell_type":"markdown","metadata":{"id":"TM6jFT4NzcG6"},"source":["# Extracting Keypoints Values"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"elapsed":365,"status":"error","timestamp":1644650710445,"user":{"displayName":"Nisarg Khacharia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhU9oWwobGpgFORhEv1KqSZ0ib2zhbu4wHOtw6uhA=s64","userId":"12217861741112456528"},"user_tz":-330},"id":"p9sI-hyKzcG6","outputId":"22e82d82-49de-465e-ec83-edbe7d2d5bad"},"outputs":[],"source":["pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n","face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n","lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n","rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"P3okSNdszcG8"},"outputs":[],"source":["def extract_keypoints(results):\n","    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n","    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n","    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n","    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n","    \n","    return np.concatenate([pose, lh, rh])"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"xx_WlTuczcG8","outputId":"25e01421-d493-4038-c5d9-a6a802033a47"},"outputs":[{"data":{"text/plain":["(258,)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["extract_keypoints(results).shape"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"i2PQXcMxzcG9","outputId":"e6a80180-18fa-4060-e829-b32e74f2709a"},"outputs":[{"data":{"text/plain":["258"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["33*4 + 21*3 + 21*3"]},{"cell_type":"markdown","metadata":{"id":"35ag9ICGzcG9"},"source":["# Setup Folders"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"79s6dK00zcG9"},"outputs":[],"source":["# Path for exported data, numpy arrays\n","DATA_PATH = os.path.join('MP_Data_NoFace') \n","\n","lst = ['Amazed', 'Bad', 'Correct', 'Day', 'Deaf', 'Difficult', 'Good Afternoon',\n","       'Good Morning', 'Hearing', 'Hello', 'How Are You', 'My Name is', 'Namaste', 'Peace',\n","       'Sign', 'Sorry', 'Strong', 'ThankYou']\n","\n","# Actions that we try to detect\n","actions = np.array(['NO ACTION', 'Hello', 'Good Morning', 'Day', 'How Are You'])\n","\n","# Thirty videos worth of data\n","no_sequences = 100\n","\n","# Videos are going to be 30 frames in length\n","sequence_length = 30"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"dpy0oTBPzcG-"},"outputs":[],"source":["for action in actions: \n","    for sequence in range(0, no_sequences):\n","        try: \n","            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n","        except:\n","            pass"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"xzwgOrLizcG-"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32md:\\Work & Study\\Projects\\Sign Language Recognition\\Sign Detection.ipynb Cell 17'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000016?line=13'>14</a>\u001b[0m                 ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000016?line=15'>16</a>\u001b[0m                 \u001b[39m# Make detections\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000016?line=16'>17</a>\u001b[0m                 image, results \u001b[39m=\u001b[39m mediapipe_detection(frame, holistic)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000016?line=17'>18</a>\u001b[0m \u001b[39m#                 print(results)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000016?line=18'>19</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000016?line=19'>20</a>\u001b[0m                 \u001b[39m# Draw landmarks\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000016?line=20'>21</a>\u001b[0m                 draw_landmarks(image, results)\n","\u001b[1;32md:\\Work & Study\\Projects\\Sign Language Recognition\\Sign Detection.ipynb Cell 5'\u001b[0m in \u001b[0;36mmediapipe_detection\u001b[1;34m(image, model)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000004?line=1'>2</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(image, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000004?line=2'>3</a>\u001b[0m image\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m         \u001b[39m# image not writeable\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000004?line=3'>4</a>\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mprocess(image)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000004?line=4'>5</a>\u001b[0m image\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m          \u001b[39m# image writeable\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Work%20%26%20Study/Projects/Sign%20Language%20Recognition/Sign%20Detection.ipynb#ch0000004?line=5'>6</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(image, cv2\u001b[39m.\u001b[39mCOLOR_RGB2BGR)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\mediapipe\\python\\solutions\\holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solutions/holistic.py?line=135'>136</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m, image: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NamedTuple:\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solutions/holistic.py?line=136'>137</a>\u001b[0m   \u001b[39m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solutions/holistic.py?line=137'>138</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solutions/holistic.py?line=138'>139</a>\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solutions/holistic.py?line=156'>157</a>\u001b[0m \u001b[39m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solutions/holistic.py?line=157'>158</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solutions/holistic.py?line=159'>160</a>\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mprocess(input_data\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m: image})\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solutions/holistic.py?line=160'>161</a>\u001b[0m   \u001b[39mif\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks:\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solutions/holistic.py?line=161'>162</a>\u001b[0m     \u001b[39mfor\u001b[39;00m landmark \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks\u001b[39m.\u001b[39mlandmark:\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\mediapipe\\python\\solution_base.py:334\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solution_base.py?line=327'>328</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solution_base.py?line=328'>329</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solution_base.py?line=329'>330</a>\u001b[0m         stream\u001b[39m=\u001b[39mstream_name,\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solution_base.py?line=330'>331</a>\u001b[0m         packet\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solution_base.py?line=331'>332</a>\u001b[0m                                  data)\u001b[39m.\u001b[39mat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solution_base.py?line=333'>334</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph\u001b[39m.\u001b[39;49mwait_until_idle()\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solution_base.py?line=334'>335</a>\u001b[0m \u001b[39m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solution_base.py?line=335'>336</a>\u001b[0m \u001b[39m# output stream names.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solution_base.py?line=336'>337</a>\u001b[0m solution_outputs \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mnamedtuple(\n\u001b[0;32m    <a href='file:///c%3A/Users/nisar/AppData/Roaming/Python/Python39/site-packages/mediapipe/python/solution_base.py?line=337'>338</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSolutionOutputs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_stream_type_info\u001b[39m.\u001b[39mkeys())\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["cap = cv2.VideoCapture(0)\n","# Set mediapipe model \n","with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n","    \n","    # NEW LOOP\n","    # Loop through actions\n","    for action in actions:\n","        # Loop through sequences aka videos\n","        for sequence in range(0, no_sequences):\n","            # Loop through video length aka sequence length\n","            for frame_num in range(sequence_length):\n","\n","                # Read feed\n","                ret, frame = cap.read()\n","\n","                # Make detections\n","                image, results = mediapipe_detection(frame, holistic)\n","#                 print(results)\n","\n","                # Draw landmarks\n","                draw_landmarks(image, results)\n","                \n","                # NEW Apply wait logic\n","                if frame_num == 0: \n","                    cv2.putText(image, 'STARTING COLLECTION', (120,200), \n","                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n","                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n","                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n","                    # Show to screen\n","                    cv2.imshow('OpenCV Feed', image)\n","                    cv2.waitKey(2000)\n","                else: \n","                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n","                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n","                    # Show to screen\n","                    cv2.imshow('OpenCV Feed', image)\n","                \n","                # NEW Export keypoints\n","                keypoints = extract_keypoints(results)\n","                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n","                np.save(npy_path, keypoints)\n","\n","                # Break gracefully\n","                if cv2.waitKey(10) & 0xFF == 27:\n","                    break\n","                    \n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["cv2.destroyAllWindows()\n","cap.release()"]},{"cell_type":"markdown","metadata":{"id":"qINsFr8lzcG-"},"source":["# Preprocess Data and Create Labels and Features"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"-5Dwqs3vzcG-"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"z3fgYYljzcG_"},"outputs":[],"source":["label_map = {label:num for num, label in enumerate(actions)}"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"k36DvvZ1zcG_","outputId":"f6e7eb88-8404-40b3-eed2-21a2db3e97fd"},"outputs":[{"data":{"text/plain":["{'NO ACTION': 0, 'Hello': 1, 'Good Morning': 2, 'Day': 3, 'How Are You': 4}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["label_map"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"rbBvCWdtzcG_"},"outputs":[],"source":["sequences, labels = [], []\n","for action in actions:\n","    for sequence in range(0, 100):\n","        window = []\n","        for frame_num in range(sequence_length):\n","            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n","            window.append(res)\n","        sequences.append(window)\n","        labels.append(label_map[action])"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"QTKgwbShzcG_","outputId":"eb6f9f89-25d7-42e3-b7fa-baaa3e1355fc"},"outputs":[{"data":{"text/plain":["(500, 30, 258)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["np.array(sequences).shape"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"w3aZ7dd0zcHA","outputId":"86c23066-bc1d-4c5f-8d8c-bde8af40ce20"},"outputs":[{"data":{"text/plain":["(500,)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["np.array(labels).shape"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"1CZGwRQtzcHA"},"outputs":[],"source":["X = np.array(sequences)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"79uaKkYTzcHA"},"outputs":[],"source":["y = to_categorical(labels).astype(int)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"jY8GBwUYzcHA"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"]},{"cell_type":"markdown","metadata":{"id":"w-AsOZpozcHA"},"source":["# Build and Train LSTM Neural Network"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"V0lUbQ9tzcHB"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from tensorflow.keras.callbacks import TensorBoard"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"j9W2wCi-zcHB"},"outputs":[],"source":["log_dir = os.path.join('Logs')\n","tb_callback = TensorBoard(log_dir=log_dir)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"LO1tcTk6zcHB","outputId":"c38af6a5-bf49-4d3a-82fc-08ac87a1fe84"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}],"source":["model = Sequential()\n","model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,258)))\n","model.add(LSTM(128, return_sequences=True, activation='relu'))\n","model.add(LSTM(64, return_sequences=False, activation='relu'))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(actions.shape[0], activation='softmax'))"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"zHTf7Z8VzcHB"},"outputs":[],"source":["res = [.7, 0.2, 0.1]"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"RgYlQ1JkzcHB","outputId":"05a3bf31-1921-46ed-d138-d27312f8f378"},"outputs":[{"data":{"text/plain":["'NO ACTION'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["actions[np.argmax(res)]"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"mcXu0qVdzcHB"},"outputs":[],"source":["model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"B-QRuwqMzcHC","outputId":"26773ed3-8faf-4404-bc20-8f7379c3f040","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n","15/15 [==============================] - 4s 144ms/step - loss: 1.3023 - categorical_accuracy: 0.3663\n","Epoch 2/150\n","15/15 [==============================] - 2s 148ms/step - loss: 1.2061 - categorical_accuracy: 0.5474\n","Epoch 3/150\n","15/15 [==============================] - 2s 149ms/step - loss: 0.6984 - categorical_accuracy: 0.8463\n","Epoch 4/150\n","15/15 [==============================] - 2s 151ms/step - loss: 0.2274 - categorical_accuracy: 0.9453\n","Epoch 5/150\n","15/15 [==============================] - 2s 163ms/step - loss: 0.2332 - categorical_accuracy: 0.9389\n","Epoch 6/150\n","15/15 [==============================] - 3s 189ms/step - loss: 0.2211 - categorical_accuracy: 0.9537\n","Epoch 7/150\n","15/15 [==============================] - 2s 149ms/step - loss: 0.0738 - categorical_accuracy: 0.9895\n","Epoch 8/150\n","15/15 [==============================] - 2s 151ms/step - loss: 0.2476 - categorical_accuracy: 0.9537\n","Epoch 9/150\n","15/15 [==============================] - 3s 172ms/step - loss: 0.2085 - categorical_accuracy: 0.9474\n","Epoch 10/150\n","15/15 [==============================] - 2s 149ms/step - loss: 0.4683 - categorical_accuracy: 0.8884\n","Epoch 11/150\n","15/15 [==============================] - 2s 158ms/step - loss: 0.1604 - categorical_accuracy: 0.9663\n","Epoch 12/150\n","15/15 [==============================] - 2s 155ms/step - loss: 0.0465 - categorical_accuracy: 0.9979\n","Epoch 13/150\n","15/15 [==============================] - 2s 156ms/step - loss: 0.1237 - categorical_accuracy: 0.9663\n","Epoch 14/150\n","15/15 [==============================] - 2s 136ms/step - loss: 0.0406 - categorical_accuracy: 0.9937\n","Epoch 15/150\n","15/15 [==============================] - 2s 141ms/step - loss: 0.0107 - categorical_accuracy: 0.9958\n","Epoch 16/150\n","15/15 [==============================] - 2s 139ms/step - loss: 0.0045 - categorical_accuracy: 1.0000\n","Epoch 17/150\n"," 7/15 [=============>................] - ETA: 1s - loss: 0.0024 - categorical_accuracy: 1.0000"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[tb_callback])\n","File \u001b[1;32m~\\anaconda3\\envs\\sign\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32m~\\anaconda3\\envs\\sign\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[1;32m~\\anaconda3\\envs\\sign\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32m~\\anaconda3\\envs\\sign\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[1;32m~\\anaconda3\\envs\\sign\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[1;32m~\\anaconda3\\envs\\sign\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[1;32m~\\anaconda3\\envs\\sign\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[1;32m~\\anaconda3\\envs\\sign\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[1;32m~\\anaconda3\\envs\\sign\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///~/anaconda3/envs/sign/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model.fit(X_train, y_train, epochs=150, callbacks=[tb_callback])"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"2RQOAcNazcHC","outputId":"b38c97bb-f51d-4c40-c8bf-c086eb0184db"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_2 (LSTM)               (None, 30, 32)            37248     \n","                                                                 \n"," lstm_3 (LSTM)               (None, 64)                24832     \n","                                                                 \n"," dense_3 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_4 (Dense)             (None, 32)                1056      \n","                                                                 \n"," dense_5 (Dense)             (None, 5)                 165       \n","                                                                 \n","=================================================================\n","Total params: 65,381\n","Trainable params: 65,381\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"9316ZGyOzcHC"},"source":["# Make Predictions"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"fIV_SxDazcHC"},"outputs":[],"source":["res = model.predict(X_test)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"FfO7Ruc3zcHC","outputId":"ae8b6803-80d1-420e-9878-76ffe347344f"},"outputs":[{"data":{"text/plain":["'Good Morning'"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["actions[np.argmax(res[2])]"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"tLcYl9GqzcHD","outputId":"eb7ab6a6-06d9-4efa-c172-ed7f98d6c5e8"},"outputs":[{"data":{"text/plain":["'Good Morning'"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["actions[np.argmax(y_test[2])]"]},{"cell_type":"markdown","metadata":{"id":"ExLrGnIkzcHD"},"source":["# Save Model"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"P_bLgrLnzcHD"},"outputs":[],"source":["#model.save('Sign-Noface-tuned-3.h5')"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"aqrn7v0AzcHD"},"outputs":[],"source":["model.load_weights('Fine Working Models\\Sign-GM-Day-Hello-HRY.h5')"]},{"cell_type":"markdown","metadata":{"id":"QVdlzDTxzcHD"},"source":["# Evaluation using Confusion Matrix and Accuracy"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"twd5gwG7zcHD"},"outputs":[],"source":["from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"OmhYJT7SzcHD"},"outputs":[],"source":["yhat = model.predict(X_test)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"br2JFihMzcHD"},"outputs":[],"source":["ytrue = np.argmax(y_test, axis=1).tolist()\n","yhat = np.argmax(yhat, axis=1).tolist()"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"QbZBo--jzcHE","outputId":"30f5ccb6-901c-437f-b00b-4a655a05f3af"},"outputs":[{"data":{"text/plain":["array([[[21,  0],\n","        [ 0,  4]],\n","\n","       [[19,  0],\n","        [ 0,  6]],\n","\n","       [[18,  0],\n","        [ 0,  7]],\n","\n","       [[23,  0],\n","        [ 0,  2]],\n","\n","       [[19,  0],\n","        [ 0,  6]]], dtype=int64)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["multilabel_confusion_matrix(ytrue, yhat)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"Ix06IxzkzcHE","outputId":"d5a7098e-0580-486b-bb80-3085752e819d"},"outputs":[{"name":"stdout","output_type":"stream","text":["The accuracy score on testing data is: 100.0%\n"]}],"source":["print ('The accuracy score on testing data is: {}%'.format(accuracy_score(ytrue, yhat) * 100))"]},{"cell_type":"markdown","metadata":{},"source":["# 11. Test in Real Time"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["#colors = [(245,117,16), (117,245,16), (16,117,245)]\n","\n","colors = [(245,117,16), (117,245,16), (16,117,245), (117,245,16), (16,117,245)]\n","def prob_viz(res, actions, input_frame, colors):\n","    output_frame = input_frame.copy()\n","    for num, prob in enumerate(res):\n","        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n","        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n","        \n","    return output_frame"]},{"cell_type":"code","execution_count":207,"metadata":{},"outputs":[],"source":["cap = cv2.VideoCapture(0)\n","# Set mediapipe model \n","with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n","    while cap.isOpened():\n","    \n","        # Read feed\n","        ret, frame = cap.read()\n","\n","        # Make detections\n","        image, results = mediapipe_detection(frame, holistic)\n","        \n","        # Draw landmarks\n","        draw_landmarks(image, results, face = True)\n","\n","        # Show to screen\n","        cv2.imshow('OpenCV Feed', image)\n","\n","        # Break gracefully\n","        if cv2.waitKey(10) & 0xFF == 27:\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["# 1. New detection variables\n","sequence = []\n","sentence = []\n","predictions = []\n","threshold = 0.8\n","\n","cap = cv2.VideoCapture(0)\n","# Set mediapipe model \n","with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n","    while cap.isOpened():\n","\n","        # Read feed\n","        ret, frame = cap.read()\n","\n","        # Make detections\n","        image, results = mediapipe_detection(frame, holistic)\n","        #print(results)\n","        \n","        # Draw landmarks\n","        draw_landmarks(image, results, face=True)\n","        \n","        # 2. Prediction logic\n","        keypoints = extract_keypoints(results)\n","        sequence.append(keypoints)\n","        sequence = sequence[-30:]\n","        \n","        if len(sequence) == 30:\n","            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n","            #print(actions[np.argmax(res)])\n","            predictions.append(np.argmax(res))\n","            \n","            \n","        #3. Viz logic\n","        #if np.unique(predictions[-10:])[0]==np.argmax(res): \n","            if res[np.argmax(res)] > threshold: \n","                \n","                if len(sentence) > 0: \n","                    if actions[np.argmax(res)] != sentence[-1]:\n","                        sentence.append(actions[np.argmax(res)])\n","                else:\n","                    sentence.append(actions[np.argmax(res)])\n","\n","            if len(sentence) > 2: \n","                sentence = sentence[-2:]\n","\n","            # Viz probabilities\n","            image = prob_viz(res, actions, image, colors)\n","            \n","        # cv2.rectangle(image, (0,440), (640, 480), (245, 117, 16), -1)\n","        # cv2.putText(image, ' '.join(sentence), (50,450), \n","        #                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n","        \n","        # Show to screen\n","        cv2.imshow('OpenCV Feed', image)\n","\n","        # Break gracefully\n","        if cv2.waitKey(10) & 0xFF == 27:\n","            break\n","    cap.release()\n","    cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["cv2.destroyAllWindows()\n","cap.release()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"Sign Detection.ipynb","provenance":[]},"interpreter":{"hash":"18b83245f4226537c0297435ef69d007665da2ba477db7397a4bbf149670d27b"},"kernelspec":{"display_name":"Python 3.9.0 ('sign')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
